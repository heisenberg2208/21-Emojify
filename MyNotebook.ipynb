{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emojify!\n",
    "\n",
    "Have you ever wanted to make your text messages more expressive? Your emojifier app will help you do that. So rather than writing \"Congratulations on the promotion! Lets get coffee and talk. Love you!\" the emojifier can automatically turn this into \"Congratulations on the promotion! üëç Lets get coffee and talk. ‚òïÔ∏è Love you! ‚ù§Ô∏è\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from emo_utils import *\n",
    "import emoji\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Baseline model: Emojifier-V1\n",
    "\n",
    "### 1.1 - Dataset EMOJISET\n",
    "\n",
    "You have a tiny dataset (X, Y) where:\n",
    "- X contains 127 sentences (strings)\n",
    "- Y contains a integer label between 0 and 4 corresponding to an emoji for each sentence\n",
    "\n",
    "<img src=\"images/data_set.png\" style=\"width:700px;height:300px;\">\n",
    "<caption><center> **Figure 1**: EMOJISET - a classification problem with 5 classes. A few examples of sentences are given here. </center></caption>\n",
    "\n",
    "Let's load the dataset using the code below. We split the dataset between training (127 examples) and testing (56 examples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = read_csv('data/train_emoji.csv')\n",
    "X_test, Y_test = read_csv('data/tesss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLen = len(max(X_train,key=len).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am proud of your achievements üòÑ\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "print(X_train[index], label_to_emoji(Y_train[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Overview of the Emojifier-V1\n",
    "\n",
    "<center>\n",
    "<img src=\"images/image_1.png\" style=\"width:900px;height:300px;\">\n",
    "<caption><center> **Figure 2**: Baseline model (Emojifier-V1).</center></caption>\n",
    "</center>\n",
    "\n",
    "To get our labels into a format suitable for training a softmax classifier, lets convert $Y$ from its current shape  current shape $(m, 1)$ into a \"one-hot representation\" $(m, 5)$, where each row is a one-hot vector giving the label of one example, You can do so using this next code snipper. Here, `Y_oh` stands for \"Y-one-hot\" in the variable names `Y_oh_train` and `Y_oh_test`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_oh_train = convert_to_one_hot(Y_train, C = 5)\n",
    "Y_oh_test = convert_to_one_hot(Y_test, C = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 is converted into one hot [0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "index=1\n",
    "print(Y_train[index],'is converted into one hot',Y_oh_train[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 - Implementing Emojifier-V1\n",
    "\n",
    "we will use pretrained 50-dimensional GloVe embeddings. Run the following cell to load the `word_to_vec_map`, which contains all the vector representations.\n",
    "\n",
    "- `word_to_index`: dictionary mapping from words to their indices in the vocabulary (400,001 words, with the valid indices ranging from 0 to 400,000)\n",
    "- `index_to_word`: dictionary mapping from indices to their corresponding words in the vocabulary\n",
    "- `word_to_vec_map`: dictionary mapping words to their GloVe vector representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('data/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the index of  cucumber  in the vocabulary is  113317\n",
      "the  289846 th word in the vocabulary is  potatos\n"
     ]
    }
   ],
   "source": [
    "word = 'cucumber'\n",
    "index = 289846\n",
    "print('the index of ',word, ' in the vocabulary is ',word_to_index[word])\n",
    "print('the ',str(index),'th word in the vocabulary is ', index_to_word[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_avg(sentence, word_to_vec_map):\n",
    "    words = sentence.lower().split()\n",
    "    avg = np.zeros([50,])\n",
    "    for w in words:\n",
    "        avg += word_to_vec_map[w]\n",
    "    avg = avg/len(words)\n",
    "    \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg =  [-0.008005    0.56370833 -0.50427333  0.258865    0.55131103  0.03104983\n",
      " -0.21013718  0.16893933 -0.09590267  0.141784   -0.15708967  0.18525867\n",
      "  0.6495785   0.38371117  0.21102167  0.11301667  0.02613967  0.26037767\n",
      "  0.05820667 -0.01578167 -0.12078833 -0.02471267  0.4128455   0.5152061\n",
      "  0.38756167 -0.898661   -0.535145    0.33501167  0.68806933 -0.2156265\n",
      "  1.797155    0.10476933 -0.36775333  0.750785    0.10282583  0.348925\n",
      " -0.27262833  0.66768    -0.10706167 -0.283635    0.59580117  0.28747333\n",
      " -0.3366635   0.23393817  0.34349183  0.178405    0.1166155  -0.076433\n",
      "  0.1445417   0.09808667]\n"
     ]
    }
   ],
   "source": [
    "avg = sentence_to_avg(\"Morrocan couscous is my favorite dish\", word_to_vec_map)\n",
    "print(\"avg = \", avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model\n",
    "\n",
    "Implement the `model()` function described in Figure (2). Assuming here that $Yoh$ (\"Y one hot\") is the one-hot encoding of the output labels, the equations you need to implement in the forward pass and to compute the cross-entropy cost are:\n",
    "$$ z^{(i)} = W \\times avg^{(i)} + b$$\n",
    "$$ a^{(i)} = softmax(z^{(i)})$$\n",
    "$$ \\mathcal{L}^{(i)} = - \\sum_{k = 0}^{n_y - 1} Yoh^{(i)}_k * log(a^{(i)}_k)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, word_to_vec_map, learning_rate = 0.01, num_iterations = 400):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X -- input data, numpy array of sentences as strings, of shape (m, 1)\n",
    "    Y -- labels, numpy array of integers between 0 and 7, numpy-array of shape (m, 1)\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "    learning_rate -- learning_rate for the stochastic gradient descent algorithm\n",
    "    num_iterations -- number of iterations\n",
    "    \n",
    "    Returns:\n",
    "    pred -- vector of predictions, numpy-array of shape (m, 1)\n",
    "    W -- weight matrix of the softmax layer, of shape (n_y, n_h)\n",
    "    b -- bias of the softmax layer, of shape (n_y,)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    \n",
    "    m = Y.shape[0]\n",
    "    n_y = 5\n",
    "    n_h = 50\n",
    "    \n",
    "    W = np.random.randn(n_y,n_h)/np.sqrt(n_h)\n",
    "    b = np.zeros((n_y,))\n",
    "    \n",
    "    Y_oh = convert_to_one_hot(Y, C = n_y)\n",
    "    \n",
    "    for t in range(num_iterations):\n",
    "        for i in range(m):\n",
    "            avg = sentence_to_avg(X[i],word_to_vec_map)\n",
    "            \n",
    "            z = np.dot(W,avg)+b\n",
    "            a = softmax(z)\n",
    "            \n",
    "            cost = np.sum(-Y_oh[i]*np.log(a))\n",
    "            \n",
    "            dz = a - Y_oh[i]\n",
    "            dW = np.dot(dz.reshape(n_y,1), avg.reshape(1, n_h))\n",
    "            db = dz\n",
    "            \n",
    "            W = W - learning_rate*dW\n",
    "            b = b - learning_rate*db\n",
    "            \n",
    "        if t % 100 == 0:\n",
    "            print('Epoch: ' + str(t) + \"---cost = \" + str(cost))\n",
    "            pred = predict(X,Y,W,b,word_to_vec_map)\n",
    "    \n",
    "    return pred, W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132,)\n",
      "(132,)\n",
      "(132, 5)\n",
      "never talk to me again\n",
      "<class 'numpy.ndarray'>\n",
      "(20,)\n",
      "(20,)\n",
      "(132, 5)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(np.eye(5)[Y_train.reshape(-1)].shape)\n",
    "print(X_train[0])\n",
    "print(type(X_train))\n",
    "Y = np.asarray([5,0,0,5, 4, 4, 4, 6, 6, 4, 1, 1, 5, 6, 6, 3, 6, 3, 4, 4])\n",
    "print(Y.shape)\n",
    "\n",
    "X = np.asarray(['I am going to the bar tonight', 'I love you', 'miss you my dear',\n",
    " 'Lets go party and drinks','Congrats on the new job','Congratulations',\n",
    " 'I am so happy for you', 'Why are you feeling bad', 'What is wrong with you',\n",
    " 'You totally deserve this prize', 'Let us go play football',\n",
    " 'Are you down for football this afternoon', 'Work hard play harder',\n",
    " 'It is suprising how people can be dumb sometimes',\n",
    " 'I am very disappointed','It is the best day in my life',\n",
    " 'I think I will end up alone','My life is so boring','Good job',\n",
    " 'Great so awesome'])\n",
    "\n",
    "print(X.shape)\n",
    "print(np.eye(5)[Y_train.reshape(-1)].shape)\n",
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0---cost = 1.9520498812810072\n",
      "Accuracy: 0.3484848484848485\n",
      "Epoch: 100---cost = 0.07971818726014807\n",
      "Accuracy: 0.9318181818181818\n",
      "Epoch: 200---cost = 0.04456369243681402\n",
      "Accuracy: 0.9545454545454546\n",
      "Epoch: 300---cost = 0.03432267378786059\n",
      "Accuracy: 0.9696969696969697\n",
      "[[3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [0.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [1.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [3.]\n",
      " [1.]\n",
      " [0.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "pred, W, b = model(X_train, Y_train, word_to_vec_map)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 - Examining test set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Accuracy: 0.9772727272727273\n",
      "test set:\n",
      "Accuracy: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set:\")\n",
    "pred_train = predict(X_train, Y_train, W, b, word_to_vec_map)\n",
    "print(\"test set:\")\n",
    "pred_test = predict(X_test, Y_test, W, b, word_to_vec_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8333333333333334\n",
      "\n",
      "i adore you ‚ù§Ô∏è\n",
      "i love you ‚ù§Ô∏è\n",
      "funny lol üòÑ\n",
      "lets play with a ball ‚öæ\n",
      "food is ready üç¥\n",
      "not feeling happy üòÑ\n"
     ]
    }
   ],
   "source": [
    "X_my_sentences = np.array([\"i adore you\", \"i love you\", \"funny lol\", \"lets play with a ball\", \"food is ready\", \"not feeling happy\"])\n",
    "Y_my_labels = np.array([[0], [0], [2], [1], [4],[3]])\n",
    "\n",
    "pred = predict(X_my_sentences, Y_my_labels , W, b, word_to_vec_map)\n",
    "print_predictions(X_my_sentences, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56,)\n",
      "           ‚ù§Ô∏è    ‚öæ    üòÑ    üòû   üç¥\n",
      "Predicted  0.0  1.0  2.0  3.0  4.0  All\n",
      "Actual                                 \n",
      "0            6    0    0    1    0    7\n",
      "1            0    8    0    0    0    8\n",
      "2            2    0   16    0    0   18\n",
      "3            1    1    2   12    0   16\n",
      "4            0    0    1    0    6    7\n",
      "All          9    9   19   13    6   56\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(Y_test.shape)\n",
    "print('           '+ label_to_emoji(0)+ '    ' + label_to_emoji(1) + '    ' +  label_to_emoji(2)+ '    ' + label_to_emoji(3)+'   ' + label_to_emoji(4))\n",
    "print(pd.crosstab(Y_test, pred_test.reshape(56,), rownames=['Actual'], colnames=['Predicted'], margins=True))\n",
    "plot_confusion_matrix(Y_test, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Emojifier-V2 : Using LSTMs in keras:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Overview of the model\n",
    "\n",
    "<img src=\"images/emojifier-v2.png\" style=\"width:700px;height:400px;\"> <br>\n",
    "<caption><center> **Figure 3**: Emojifier-V2. A 2-layer LSTM sequence classifier. </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Keras and mini-batching\n",
    "\n",
    " If you had a 3-word sentence and a 4-word sentence, then the computations needed for them are different (one takes 3 steps of an LSTM, one takes 4 steps) so it's just not possible to do them both at the same time.The common solution to this is to use padding. Specifically, set a maximum sequence length, and pad all sequences to the same length. For example, of the maximum sequence length is 20, we could pad every sentence with \"0\"s so that each input sentence is of length 20. Thus, a sentence \"i love you\" would be represented as $(e_{i}, e_{love}, e_{you}, \\vec{0}, \\vec{0}, \\ldots, \\vec{0})$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - The Embedding Layer\n",
    "\n",
    "<img src=\"images/embedding1.png\" style=\"width:700px;height:250px;\">\n",
    "<caption><center> **Figure 4**: Embedding layer. This example shows the propagation of two examples through the embedding layer. Both have been zero-padded to a length of `max_len=5`. The final dimension of the representation is  `(2,max_len,50)` because the word embeddings we are using are 50 dimensional. </center></caption>\n",
    "\n",
    "Implement the function below to convert X (array of sentences as strings) into an array of indices corresponding to words in the sentences. The output shape should be such that it can be given to `Embedding()` (described in Figure 4). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X -- array of sentences (strings), of shape (m, 1)\n",
    "    word_to_index -- a dictionary containing the each word mapped to its index\n",
    "    max_len -- maximum number of words in a sentence. You can assume every sentence in X is no longer than this. \n",
    "    \n",
    "    Returns:\n",
    "    X_indices -- array of indices corresponding to words in the sentences from X, of shape (m, max_len)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    X_indices = np.zeros((m,max_len))\n",
    "    \n",
    "    for i in range(m):\n",
    "        sentence_i_words = X[i].lower().split()\n",
    "        \n",
    "        j = 0 \n",
    "        for w in sentence_i_words:\n",
    "            X_indices[i,j] = word_to_index[w]\n",
    "            j = j + 1\n",
    "    \n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 = ['funny lol' 'lets play baseball' 'food is ready for you']\n",
      "X1_indices = [[155345. 225122.      0.      0.      0.]\n",
      " [220930. 286375.  69714.      0.      0.]\n",
      " [151204. 192973. 302254. 151349. 394475.]]\n"
     ]
    }
   ],
   "source": [
    "X1 = np.array([\"funny lol\", \"lets play baseball\", \"food is ready for you\"])\n",
    "X1_indices = sentences_to_indices(X1,word_to_index, max_len = 5)\n",
    "print(\"X1 =\", X1)\n",
    "print(\"X1_indices =\", X1_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement `pretrained_embedding_layer()`. You will need to carry out the following steps:\n",
    "1. Initialize the embedding matrix as a numpy array of zeroes with the correct shape.\n",
    "2. Fill in the embedding matrix with all the word embeddings extracted from `word_to_vec_map`.\n",
    "3. Define Keras embedding layer. Use [Embedding()](https://keras.io/layers/embeddings/). Be sure to make this layer non-trainable, by setting `trainable = False` when calling `Embedding()`. If you were to set `trainable = True`, then it will allow the optimization algorithm to modify the values of the word embeddings. \n",
    "4. Set the embedding weights to be equal to the embedding matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    word_to_vec_map -- dictionary mapping words to their GloVe vector representation.\n",
    "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
    "\n",
    "    Returns:\n",
    "    embedding_layer -- pretrained layer Keras instance\n",
    "    \"\"\"\n",
    "    \n",
    "    vocab_len = len(word_to_index) + 1 # +1 to fill keras requiremnet\n",
    "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0] #shape of e\n",
    "    \n",
    "    #step 1\n",
    "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
    "    \n",
    "    #step 2\n",
    "    for word,index in word_to_index.items():\n",
    "        emb_matrix[index,:] = word_to_vec_map[word]\n",
    "    \n",
    "    #step 3\n",
    "    embedding_layer = Embedding( vocab_len , emb_dim , trainable=False )\n",
    "    embedding_layer.build((None,))\n",
    "    \n",
    "    #step 4\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights[0][1][3] = -0.3403\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "print(\"weights[0][1][3] =\", embedding_layer.get_weights()[0][1][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Building the Emojifier - V2\n",
    "\n",
    "<img src=\"images/emojifier-v2.png\" style=\"width:700px;height:400px;\"> <br>\n",
    "<caption><center> **Figure 3**: Emojifier-v2. A 2-layer LSTM sequence classifier. </center></caption>\n",
    "\n",
    "Implement `Emojify_V2()`, which builds a Keras graph of the architecture shown in Figure 3. The model takes as input an array of sentences of shape (`m`, `max_len`, ) defined by `input_shape`. It should output a softmax probability vector of shape (`m`, `C = 5`). You may need `Input(shape = ..., dtype = '...')`, [LSTM()](https://keras.io/layers/recurrent/#lstm), [Dropout()](https://keras.io/layers/core/#dropout), [Dense()](https://keras.io/layers/core/#dense), and [Activation()](https://keras.io/activations/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Emojify_V2(input_shape, word_to_vec_map, word_to_index):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    input_shape -- shape of the input, usually (max_len,)\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
    "\n",
    "    Returns:\n",
    "    model -- a model instance in Keras\n",
    "    \"\"\"\n",
    "    #define input to graph\n",
    "    sentence_indices = Input(shape=input_shape,dtype='int32')\n",
    "    \n",
    "    #create embedding layer\n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "    \n",
    "    #propagate sentence through embedding layer\n",
    "    embeddings = embedding_layer(sentence_indices)\n",
    "    \n",
    "    #propagate embeddings through LSTM and return_sequence = True because you want op at each sequence state\n",
    "    X = LSTM(128, return_sequences=True)(embeddings)\n",
    "    \n",
    "    #propagate sequence generated in above through dropouts\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    #propagate sequence generated in above throught LSTM where one common output will be generated\n",
    "    X = LSTM(128)(X)\n",
    "    \n",
    "    #This output is fed to dropout\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    #Dense this output to represent 5 classes for emojis\n",
    "    X = Dense(5,)(X)\n",
    "    \n",
    "    #applying softmax\n",
    "    X = Activation('softmax')(X)\n",
    "    \n",
    "    #create model\n",
    "    model = Model(inputs = sentence_indices, outputs = X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 10, 50)            20000050  \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 10, 128)           91648     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 20,223,927\n",
      "Trainable params: 223,877\n",
      "Non-trainable params: 20,000,050\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Emojify_V2((maxLen,), word_to_vec_map, word_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, after creating your model in Keras, you need to compile it and define what loss, optimizer and metrics your are want to use. Compile your model using `categorical_crossentropy` loss, `adam` optimizer and `['accuracy']` metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer = 'adam' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_indices = sentences_to_indices(X_train , word_to_index, maxLen)\n",
    "Y_train_oh = convert_to_one_hot(Y_train , C = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "132/132 [==============================] - 3s 24ms/step - loss: 1.5890 - acc: 0.2652\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 1.5390 - acc: 0.3030\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.4704 - acc: 0.3712\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 1.4399 - acc: 0.3939\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 1.3696 - acc: 0.4773\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.2215 - acc: 0.5227\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.1347 - acc: 0.5379\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.9987 - acc: 0.6136\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.9660 - acc: 0.6667\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.7485 - acc: 0.7500\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.6546 - acc: 0.7879\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.8031 - acc: 0.7652\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.5255 - acc: 0.8409\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.6890 - acc: 0.7348\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.5683 - acc: 0.7576\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.5737 - acc: 0.7955\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4590 - acc: 0.8712\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4117 - acc: 0.8788\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3766 - acc: 0.8636\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3532 - acc: 0.9015\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3416 - acc: 0.8864\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.2780 - acc: 0.9167\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.2755 - acc: 0.9167\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.2544 - acc: 0.9167\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.2808 - acc: 0.8864\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.2727 - acc: 0.9015\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3150 - acc: 0.8939\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.2598 - acc: 0.8864\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.2660 - acc: 0.9242\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.2406 - acc: 0.9015\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3200 - acc: 0.8864\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1765 - acc: 0.9621\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3171 - acc: 0.8864\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1526 - acc: 0.9545\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1553 - acc: 0.9621\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1248 - acc: 0.9697\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1145 - acc: 0.9621\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1678 - acc: 0.9394\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0799 - acc: 0.9848\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0614 - acc: 0.9848\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0735 - acc: 0.9773\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0386 - acc: 0.9848\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0380 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0251 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0196 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0153 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0306 - acc: 0.9924\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0119 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0121 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0076 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f57125435f8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices, Y_train_oh , epochs = 50 , batch_size = 32 , shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 7ms/step\n",
      "\n",
      "Test accuracy =  0.8928571513720921\n"
     ]
    }
   ],
   "source": [
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_len = maxLen)\n",
    "Y_test_oh = convert_to_one_hot(Y_test, C = 5)\n",
    "loss, acc = model.evaluate(X_test_indices, Y_test_oh)\n",
    "print()\n",
    "print(\"Test accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not feeling happy üòû\n"
     ]
    }
   ],
   "source": [
    "# Change the sentence below to see your prediction. Make sure all the words are in the Glove embeddings.  \n",
    "x_test = np.array(['not feeling happy'])\n",
    "X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n",
    "print(x_test[0] +' '+  label_to_emoji(np.argmax(model.predict(X_test_indices))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
